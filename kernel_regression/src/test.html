<p>In the interactive figure, data points $(x_i, y_i)$ are shown as black dots.  There is one Gaussian centered at each $x_i$.  The blue curve is a linear combination $(\alpha_1, \cdots, \alpha_n)$ of these Gaussians.  Each slider controls one of the $\alpha_i$.</p>
<p>You can adjust the sliders to make the blue curve perfectly fit the $y_i$.  It may be surprising to note that a unique, perfect-fitting $\alpha$ exists for any set of $(x_i, y_i)$ and for any number of points.</p>
<p>To see why, note that each gray curve&#39;s set of values along the $x_i$ produces a vector.  (You can toggle the &#39;points&#39; checkbox to see these.  Denoting the j&#39;th curve as $k_j(x)$, the set of values it produces is $(k_j(x_1), k_j(x_2), \cdots, k_j(x_n))$.  Particularly for a collection of Gaussians all with the same $\sigma$, the set of these $n$ vectors are linearly independent.  This is not at all obvious, but please accept it for now.  Then, by the linear algebra expansion theorem, they span $\mathbb{R}^n$ and so can form any set of $(y_i)$.</p>
<p>Explicitly:</p>
<p>$
\begin{aligned}
k_j(x) &amp; &amp; \mbox{Gaussians centered at $x_j$, $j = 1 .. n$} \
f(x) &amp; \equiv \sum_j { \alpha_j k_j(x) } &amp; \mbox{the blue curve}\
f(x_i) &amp; = \sum_j { \alpha_j k_j(x_i) } = y_i &amp; \mbox{fitting the blue curve to the black points} \
\B{\alpha K} &amp; = \B{y} , &amp; \mbox{defining $K_{ji} \equiv k_j(x_i)$, same equations, in matrix form} \
\end{aligned}
$</p>
<p>The $\B{\alpha}$ that fits the data perfectly is found by inverting $\B{K}$, which is possible because $\B{K}$ is full-rank.  That is, its rows are linearly independent, due to the property of a collections of Gaussians of the same $\sigma$.  Even though we are taking linear combinations of functions, it is only the tuple of function values $(f_j(x_1), \cdots, f_j(x_n))$ which affects the choice of $\B{\alpha}$.</p>
<p><strong>This method can fit any set of data in $\mathbb{R} \times \mathbb{R}$.</strong>  Given a <em>particular</em> set $x_i$, you could hand-pick a set of functions $k_j(\cdot)$ which happen to produce linearly independent vectors $(k_j(x_i))$ of evaluation on that particular data set.  However, the procedure shown above can fit any data set $(x_i, y_i)$.  This is useful because it would be laborious to have to hand-pick functions for each new data set.</p>
<p><strong>There is nothing (yet) special about the Gaussians being centered at the $x_i$</strong>.  It turns out that <em>any</em> choice of $n$ Gaussians will span $\mathbb{R}^n$ when evaluated at any $n$ values.  There <em>is</em> indeed something special about the Gaussians being centered at the $x_i$, but it has nothing to do with the ability to fit arbitrary data.</p>
<p><strong>Many functions have this infinite capacity</strong>.  Not just Gaussians, but many other families of functions have this capacity to perfectly fit any data, due to the vectors of evaluation being linearly independent.  Not only that, but families of functions can be found for many different domains, not just $\mathbb{R}$ as shown above.   Both discrete and continuous domains, and of arbitrary dimensions.</p>
<p><strong>Linear independence is preserved under permutation of components</strong>.  The Gaussians are able to fit any data because they produce vectors that are linearly independent.  But, note that vectors that are linearly independent would still be so, after you permute their elements all in the same way.  For vectors, there is no meaning to the ordering of the elements.  To illustrate, click the &#39;scramble&#39; button.  This reorders the x-axis in one-to-one fashion by reversing the order of every other interval of some fixed size.  Or think of it as re-ordering the components of the Gaussian &quot;vectors&quot; all in the same way, preserving their linear independence.  You can still click &#39;solve&#39; and a unique solution exists.</p>
<p>Of course, these permuted Gaussians don&#39;t have the same relationship with the original data, so there will be a different $\B{\alpha}$ solution.  This is only to show that the continuity or shape of the original Gaussians is not what gives them this capacity to fit arbitrary data.</p>
